{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble,map.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVjzUwVcmvHH",
        "outputId": "612d61b4-4b16-407a-db28-ef300f8c1159"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDkuz8Apn2ga"
      },
      "source": [
        "!pip install ensemble-boxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOtHlF2nzroF"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSoodaLxmqUJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from multiprocessing import Pool, Process, cpu_count, Manager\n",
        "from ensemble_boxes import *\n",
        "\n",
        "def process_single_id(id, res_boxes, weights, params):\n",
        "    run_type = params['run_type']\n",
        "    verbose = params['verbose']\n",
        "\n",
        "    # print('Go for ID: {}'.format(id))\n",
        "    boxes_list = []\n",
        "    scores_list = []\n",
        "    labels_list = []\n",
        "    labels_to_use_forward = dict()\n",
        "    labels_to_use_backward = dict()\n",
        "\n",
        "    for i in range(len(res_boxes[id])):\n",
        "        boxes = []\n",
        "        scores = []\n",
        "        labels = []\n",
        "\n",
        "        dt = res_boxes[id][i]\n",
        "\n",
        "        for j in range(0, len(dt)):\n",
        "            lbl = dt[j][5]\n",
        "            scr = float(dt[j][4])\n",
        "            box_x1 = float(dt[j][0]/1024)\n",
        "            box_y1 = float(dt[j][1]/1024)\n",
        "            box_x2 = float(dt[j][2]/1024)\n",
        "            box_y2 = float(dt[j][3]/1024)\n",
        "\n",
        "            if box_x1 >= box_x2:\n",
        "                if verbose:\n",
        "                    print('Problem with box x1 and x2: {}. Skip it'.format(dt[j]))\n",
        "                continue\n",
        "            if box_y1 >= box_y2:\n",
        "                if verbose:\n",
        "                    print('Problem with box y1 and y2: {}. Skip it'.format(dt[j]))\n",
        "                continue\n",
        "            if scr <= 0:\n",
        "                if verbose:\n",
        "                    print('Problem with box score: {}. Skip it'.format(dt[j]))\n",
        "                continue\n",
        "\n",
        "            boxes.append([box_x1, box_y1, box_x2, box_y2])\n",
        "            scores.append(scr)\n",
        "            if lbl not in labels_to_use_forward:\n",
        "                cur_point = len(labels_to_use_forward)\n",
        "                labels_to_use_forward[lbl] = cur_point\n",
        "                labels_to_use_backward[cur_point] = lbl\n",
        "            labels.append(labels_to_use_forward[lbl])\n",
        "\n",
        "        boxes = np.array(boxes, dtype=np.float32)\n",
        "        scores = np.array(scores, dtype=np.float32)\n",
        "        labels = np.array(labels, dtype=np.int32)\n",
        "\n",
        "        boxes_list.append(boxes)\n",
        "        scores_list.append(scores)\n",
        "        labels_list.append(labels)\n",
        "\n",
        "    # Empty predictions for all models\n",
        "    if len(boxes_list) == 0:\n",
        "        return np.array([]), np.array([]), np.array([])\n",
        "\n",
        "    if run_type == 'wbf':\n",
        "        merged_boxes, merged_scores, merged_labels = weighted_boxes_fusion(boxes_list, scores_list, labels_list,\n",
        "                                                                       weights=weights, iou_thr=params['intersection_thr'],\n",
        "                                                                       skip_box_thr=params['skip_box_thr'],\n",
        "                                                                           conf_type=params['conf_type'])\n",
        "    elif run_type == 'nms':\n",
        "        iou_thr = params['iou_thr']\n",
        "        merged_boxes, merged_scores, merged_labels = nms(boxes_list, scores_list, labels_list, weights=weights, iou_thr=iou_thr)\n",
        "    elif run_type == 'soft-nms':\n",
        "        iou_thr = params['iou_thr']\n",
        "        sigma = params['sigma']\n",
        "        thresh = params['thresh']\n",
        "        merged_boxes, merged_scores, merged_labels = soft_nms(boxes_list, scores_list, labels_list,\n",
        "                                                              weights=weights, iou_thr=iou_thr, sigma=sigma, thresh=thresh)\n",
        "    elif run_type == 'nmw':\n",
        "        merged_boxes, merged_scores, merged_labels = non_maximum_weighted(boxes_list, scores_list, labels_list,\n",
        "                                                                       weights=weights, iou_thr=params['intersection_thr'],\n",
        "                                                                       skip_box_thr=params['skip_box_thr'])\n",
        "\n",
        "    # print(len(boxes_list), len(merged_boxes))\n",
        "    if 'limit_boxes' in params:\n",
        "        limit_boxes = params['limit_boxes']\n",
        "        if len(merged_boxes) > limit_boxes:\n",
        "            merged_boxes = merged_boxes[:limit_boxes]\n",
        "            merged_scores = merged_scores[:limit_boxes]\n",
        "            merged_labels = merged_labels[:limit_boxes]\n",
        "\n",
        "    # Rename labels back\n",
        "    merged_labels_string = []\n",
        "    for m in merged_labels:\n",
        "        merged_labels_string.append(labels_to_use_backward[m])\n",
        "    merged_labels = np.array(merged_labels_string, dtype=np.str)\n",
        "\n",
        "    # Create IDs array\n",
        "    ids_list = [id] * len(merged_labels)\n",
        "\n",
        "    return merged_boxes.copy(), merged_scores.copy(), merged_labels.copy(), ids_list.copy()\n",
        "\n",
        "\n",
        "def process_part_of_data(proc_number, return_dict, ids_to_use, res_boxes, weights, params):\n",
        "    print('Start process: {} IDs to proc: {}'.format(proc_number, len(ids_to_use)))\n",
        "    result = []\n",
        "    for id in ids_to_use:\n",
        "        merged_boxes, merged_scores, merged_labels, ids_list = process_single_id(id, res_boxes, weights, params)\n",
        "        # print(merged_boxes.shape, merged_scores.shape, merged_labels.shape, len(ids_list))\n",
        "        result.append((merged_boxes, merged_scores, merged_labels, ids_list))\n",
        "    return_dict[proc_number] = result.copy()\n",
        "\n",
        "\n",
        "def ensemble_predictions(pred_filenames, weights, params):\n",
        "    verbose = False\n",
        "    if 'verbose' in params:\n",
        "        verbose = params['verbose']\n",
        "\n",
        "    start_time = time.time()\n",
        "    procs_to_use = max(cpu_count() // 2, 1)\n",
        "    # procs_to_use = 6\n",
        "    print('Use processes: {}'.format(procs_to_use))\n",
        "    weights = np.array(weights)\n",
        "\n",
        "    res_boxes = dict()\n",
        "    ref_ids = None\n",
        "    for j in range(len(pred_filenames)):\n",
        "        if weights[j] == 0:\n",
        "            continue\n",
        "        print('Read {}...'.format(pred_filenames[j]))\n",
        "        s = pd.read_csv(pred_filenames[j], dtype={'image_id': np.str, 'class': np.str})\n",
        "        s.sort_values('image_id', inplace=True)\n",
        "        s.reset_index(drop=True, inplace=True)\n",
        "        ids = s['image_id'].values\n",
        "        unique_ids = sorted(s['image_id'].unique())\n",
        "        if ref_ids is None:\n",
        "            ref_ids = tuple(unique_ids)\n",
        "        else:\n",
        "            if ref_ids != tuple(unique_ids):\n",
        "                print('Different IDs in ensembled CSVs! {} != {}'.format(len(ref_ids), len(unique_ids)))\n",
        "                s = s[s['image_id'].isin(ref_ids)]\n",
        "                s.sort_values('image_id', inplace=True)\n",
        "                s.reset_index(drop=True, inplace=True)\n",
        "                ids = s['image_id'].values\n",
        "        preds = s[['xmin', 'ymin', 'xmax', 'ymax', 'score', 'class']].values\n",
        "        single_res = dict()\n",
        "        for i in range(len(ids)):\n",
        "            id = ids[i]\n",
        "            if id not in single_res:\n",
        "                single_res[id] = []\n",
        "            single_res[id].append(preds[i])\n",
        "        for el in single_res:\n",
        "            if el not in res_boxes:\n",
        "                res_boxes[el] = []\n",
        "            res_boxes[el].append(single_res[el])\n",
        "\n",
        "    # Reduce weights if needed\n",
        "    weights = weights[weights != 0]\n",
        "    ids_to_use = sorted(list(res_boxes.keys()))\n",
        "    manager = Manager()\n",
        "    return_dict = manager.dict()\n",
        "    jobs = []\n",
        "    for i in range(procs_to_use):\n",
        "        start = i * len(ids_to_use) // procs_to_use\n",
        "        end = (i+1) * len(ids_to_use) // procs_to_use\n",
        "        if i == procs_to_use - 1:\n",
        "            end = len(ids_to_use)\n",
        "        p = Process(target=process_part_of_data, args=(i, return_dict, ids_to_use[start:end], res_boxes, weights, params))\n",
        "        jobs.append(p)\n",
        "        p.start()\n",
        "\n",
        "    for i in range(len(jobs)):\n",
        "        jobs[i].join()\n",
        "    print('helloooooooooooo')\n",
        "    results = []\n",
        "    for i in range(len(jobs)):\n",
        "        results += return_dict[i]\n",
        "\n",
        "    # p = Pool(processes=procs_to_use)\n",
        "    # results = p.starmap(process_single_id, zip(ids_to_use, repeat(weights), repeat(params)))\n",
        "\n",
        "    all_ids = []\n",
        "    all_boxes = []\n",
        "    all_scores = []\n",
        "    all_labels = []\n",
        "    for boxes, scores, labels, ids_list in results:\n",
        "        if boxes is None:\n",
        "            continue\n",
        "        all_boxes.append(boxes)\n",
        "        all_scores.append(scores)\n",
        "        all_labels.append(labels)\n",
        "        all_ids.append(ids_list)\n",
        "\n",
        "    all_ids = np.concatenate(all_ids)\n",
        "    all_boxes = np.concatenate(all_boxes)\n",
        "    all_scores = np.concatenate(all_scores)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    if verbose:\n",
        "        print(all_ids.shape, all_boxes.shape, all_scores.shape, all_labels.shape)\n",
        "\n",
        "    res = pd.DataFrame(all_ids, columns=['image_id'])\n",
        "    res['class'] = all_labels\n",
        "    res['score'] = all_scores\n",
        "    res['xmin'] = all_boxes[:, 0]*1024\n",
        "    res['ymin'] = all_boxes[:, 1] * 1024\n",
        "    res['xmax'] = all_boxes[:, 2]*1024\n",
        "    res['ymax'] = all_boxes[:, 3]*1024\n",
        "    res['width'] = all_boxes[:, 3]*0+1024\n",
        "    res['height'] = all_boxes[:, 3] * 0 + 1024\n",
        "    print('Run time: {:.2f}'.format(time.time() - start_time))\n",
        "    return res\n",
        "\n",
        "\n",
        "def ensemble(benchmark_csv, weights, params,expno):\n",
        "    ensemble_preds = ensemble_predictions(benchmark_csv, weights, params)\n",
        "    ensemble_preds.to_csv(\"/content/drive/MyDrive/Dhaka-AI 2020/handlabelEnsemble/handensemble\"+str(expno)+\".csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp65d7ky1QFC"
      },
      "source": [
        "import pandas as pd \n",
        "import io\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Aigkki1P-j"
      },
      "source": [
        "def ensemble_conf(conf_threshold, expno):\n",
        "  df = pd.read_csv(\"/content/drive/MyDrive/Dhaka-AI 2020/handlabelEnsemble/handensemble\"+str(expno)+\".csv\") \n",
        "  filename = \"handensemble\"+str(expno)\n",
        "\n",
        "  test_result = df\n",
        "  test_result['xmin'] = test_result['xmin'].astype(int)\n",
        "  test_result['ymin'] = test_result['ymin'].astype(int)\n",
        "  test_result['xmax'] = test_result['xmax'].astype(int)\n",
        "  test_result['ymax'] = test_result['ymax'].astype(int)\n",
        "  test_result['width'] = test_result['width'].astype(int)\n",
        "  test_result['height'] = test_result['height'].astype(int)\n",
        "\n",
        "  test_result = test_result.drop_duplicates(subset=['image_id','xmin','ymin','xmax','ymax'])\n",
        "\n",
        "  conf_thres = conf_threshold\n",
        "  test_result = test_result[test_result['score']>conf_thres]\n",
        "  test_result = test_result.reset_index()\n",
        "  test_result = test_result.drop(columns=['index'])\n",
        "\n",
        "  test_result.to_csv(\"/content/drive/MyDrive/Dhaka-AI 2020/handlabelEnsemble/\"+filename+\"_retouched.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX8J4puq1P7I"
      },
      "source": [
        "def ensemble_normalized(conf_thres):\n",
        "  filename = 'final_output'\n",
        "  df = pd.read_csv(\"/content/drive/MyDrive/Dhaka-AI 2020/handlabelEnsemble/final_output.csv\") \n",
        "  \n",
        "  pd.options.mode.chained_assignment = None  # default='warn'\n",
        "  test_result = df\n",
        "  for i in range(test_result['xmin'].size):\n",
        "    test_result['xmin'].iloc[i] = test_result['xmin'].iloc[i]/1024\n",
        "    test_result['ymin'].iloc[i] = test_result['ymin'].iloc[i]/1024\n",
        "    test_result['xmax'].iloc[i] = test_result['xmax'].iloc[i]/1024\n",
        "    test_result['ymax'].iloc[i] = test_result['ymax'].iloc[i]/1024\n",
        "  test_result = test_result.drop(columns=['width','height'])\n",
        "  test_result.to_csv(\"/content/drive/MyDrive/Dhaka-AI 2020/handlabelEnsemble/final_output.csv\",index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVe776cQ-B9E"
      },
      "source": [
        "def compute_overlap(boxes, query_boxes):\n",
        "    \"\"\"\n",
        "    Args\n",
        "        a: (N, 4) ndarray of float\n",
        "        b: (K, 4) ndarray of float\n",
        "    Returns\n",
        "        overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n",
        "    \"\"\"\n",
        "    N = boxes.shape[0]\n",
        "    K = query_boxes.shape[0]\n",
        "    overlaps = np.zeros((N, K), dtype=np.float64)\n",
        "    for k in range(K):\n",
        "        box_area = (\n",
        "            (query_boxes[k, 2] - query_boxes[k, 0]) *\n",
        "            (query_boxes[k, 3] - query_boxes[k, 1])\n",
        "        )\n",
        "        for n in range(N):\n",
        "            iw = (\n",
        "                min(boxes[n, 2], query_boxes[k, 2]) -\n",
        "                max(boxes[n, 0], query_boxes[k, 0])\n",
        "            )\n",
        "            if iw > 0:\n",
        "                ih = (\n",
        "                    min(boxes[n, 3], query_boxes[k, 3]) -\n",
        "                    max(boxes[n, 1], query_boxes[k, 1])\n",
        "                )\n",
        "                if ih > 0:\n",
        "                    ua = np.float64(\n",
        "                        (boxes[n, 2] - boxes[n, 0]) *\n",
        "                        (boxes[n, 3] - boxes[n, 1]) +\n",
        "                        box_area - iw * ih\n",
        "                    )\n",
        "                    overlaps[n, k] = iw * ih / ua\n",
        "    return overlaps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vLUa3d6-RWv"
      },
      "source": [
        "def get_real_annotations(table):\n",
        "    res = dict()\n",
        "    ids = table['image_id'].values.astype(np.str)\n",
        "    labels = table['class'].values.astype(np.str)\n",
        "    xmin = table['xmin'].values.astype(np.float32)\n",
        "    xmax = table['xmax'].values.astype(np.float32)\n",
        "    ymin = table['ymin'].values.astype(np.float32)\n",
        "    ymax = table['ymax'].values.astype(np.float32)\n",
        "\n",
        "    for i in range(len(ids)):\n",
        "        id = ids[i]\n",
        "        label = labels[i]\n",
        "        if id not in res:\n",
        "            res[id] = dict()\n",
        "        if label not in res[id]:\n",
        "            res[id][label] = []\n",
        "        box = [xmin[i], ymin[i], xmax[i], ymax[i]]\n",
        "        res[id][label].append(box)\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def get_detections(table):\n",
        "    res = dict()\n",
        "    ids = table['image_id'].values.astype(np.str)\n",
        "    labels = table['class'].values.astype(np.str)\n",
        "    scores = table['score'].values.astype(np.float32)\n",
        "    xmin = table['xmin'].values.astype(np.float32)\n",
        "    xmax = table['xmax'].values.astype(np.float32)\n",
        "    ymin = table['ymin'].values.astype(np.float32)\n",
        "    ymax = table['ymax'].values.astype(np.float32)\n",
        "\n",
        "    for i in range(len(ids)):\n",
        "        id = ids[i]\n",
        "        label = labels[i]\n",
        "        if id not in res:\n",
        "            res[id] = dict()\n",
        "        if label not in res[id]:\n",
        "            res[id][label] = []\n",
        "        box = [xmin[i], ymin[i], xmax[i], ymax[i], scores[i]]\n",
        "        res[id][label].append(box)\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def _compute_ap(recall, precision):\n",
        "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
        "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
        "    # Arguments\n",
        "        recall:    The recall curve (list).\n",
        "        precision: The precision curve (list).\n",
        "    # Returns\n",
        "        The average precision as computed in py-faster-rcnn.\n",
        "    \"\"\"\n",
        "    # correct AP calculation\n",
        "    # first append sentinel values at the end\n",
        "    mrec = np.concatenate(([0.], recall, [1.]))\n",
        "    mpre = np.concatenate(([0.], precision, [0.]))\n",
        "\n",
        "    # compute the precision envelope\n",
        "    for i in range(mpre.size - 1, 0, -1):\n",
        "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\n",
        "    # to calculate area under PR curve, look for points\n",
        "    # where X axis (recall) changes value\n",
        "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\n",
        "    # and sum (\\Delta recall) * prec\n",
        "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "    return ap\n",
        "\n",
        "\n",
        "def mean_average_precision_for_boxes(ann, pred, iou_threshold=0.5, exclude_not_in_annotations=False, verbose=True):\n",
        "    \"\"\"\n",
        "    :param ann: path to CSV-file with annotations or numpy array of shape (N, 6)\n",
        "    :param pred: path to CSV-file with predictions (detections) or numpy array of shape (N, 7)\n",
        "    :param iou_threshold: IoU between boxes which count as 'match'. Default: 0.5\n",
        "    :param exclude_not_in_annotations: exclude image IDs which are not exist in annotations. Default: False\n",
        "    :param verbose: print detailed run info. Default: True\n",
        "    :return: tuple, where first value is mAP and second values is dict with AP for each class.\n",
        "    \"\"\"\n",
        "\n",
        "    if isinstance(ann, str):\n",
        "        valid = pd.read_csv(ann)\n",
        "    else:\n",
        "        valid = pd.DataFrame(ann, columns=['image_id', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
        "\n",
        "    if isinstance(pred, str):\n",
        "        preds = pd.read_csv(pred)\n",
        "    else:\n",
        "        preds = pd.DataFrame(pred, columns=['image_id', 'class', 'xmin', 'ymin', 'xmax', 'ymax'])\n",
        "\n",
        "    ann_unique = valid['image_id'].unique()\n",
        "    preds_unique = preds['image_id'].unique()\n",
        "    total_ground_truth_boxes = valid.shape[0]\n",
        "    false_positives = 0\n",
        "    true_positives = 0\n",
        "\n",
        "    if verbose:\n",
        "        print('Number of files in annotations: {}'.format(len(ann_unique)))\n",
        "        print('Number of files in predictions: {}'.format(len(preds_unique)))\n",
        "\n",
        "\n",
        "    # Exclude files not in annotations!\n",
        "    if exclude_not_in_annotations:\n",
        "        preds = preds[preds['image_id'].isin(ann_unique)]\n",
        "        preds_unique = preds['image_id'].unique()\n",
        "        if verbose:\n",
        "            print('Number of files in detection after reduction: {}'.format(len(preds_unique)))\n",
        "\n",
        "    unique_classes = valid['class'].unique().astype(np.str)\n",
        "    if verbose:\n",
        "        print('Unique classes: {}'.format(len(unique_classes)))\n",
        "\n",
        "    all_detections = get_detections(preds)\n",
        "    all_annotations = get_real_annotations(valid)\n",
        "    if verbose:\n",
        "        print('Detections length: {}'.format(len(all_detections)))\n",
        "        print('Annotations length: {}'.format(len(all_annotations)))\n",
        "\n",
        "    average_precisions = {}\n",
        "    for zz, label in enumerate(sorted(unique_classes)):\n",
        "\n",
        "        # Negative class\n",
        "        if str(label) == 'nan':\n",
        "            continue\n",
        "\n",
        "        scores = []\n",
        "        num_annotations = 0.0\n",
        "\n",
        "        for i in range(len(ann_unique)):\n",
        "            detections = []\n",
        "            annotations = []\n",
        "            id = ann_unique[i]\n",
        "            if id in all_detections:\n",
        "                if label in all_detections[id]:\n",
        "                    detections = all_detections[id][label]\n",
        "            if id in all_annotations:\n",
        "                if label in all_annotations[id]:\n",
        "                    annotations = all_annotations[id][label]\n",
        "\n",
        "            if len(detections) == 0 and len(annotations) == 0:\n",
        "                continue\n",
        "\n",
        "            num_annotations += len(annotations)\n",
        "            detected_annotations = []\n",
        "\n",
        "            annotations = np.array(annotations, dtype=np.float64)\n",
        "            for d in detections:\n",
        "                scores.append(d[4])\n",
        "\n",
        "                if len(annotations) == 0:\n",
        "                    false_positives = false_positives + 1\n",
        "                    continue\n",
        "\n",
        "                overlaps = compute_overlap(np.expand_dims(np.array(d, dtype=np.float64), axis=0), annotations)\n",
        "                assigned_annotation = np.argmax(overlaps, axis=1)\n",
        "                max_overlap = overlaps[0, assigned_annotation]\n",
        "\n",
        "                if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
        "                    true_positives = true_positives + 1\n",
        "                    detected_annotations.append(assigned_annotation)\n",
        "                else:\n",
        "                    false_positives = false_positives + 1\n",
        "                   \n",
        "\n",
        "        if num_annotations == 0:\n",
        "            average_precisions[label] = 0, 0\n",
        "            continue\n",
        "\n",
        "    false_negatives = total_ground_truth_boxes - true_positives\n",
        "    mean_ap = (true_positives) / (true_positives + false_positives + false_negatives)    \n",
        "    return mean_ap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBR4hFk91P3q"
      },
      "source": [
        "def calculate_map():\n",
        "  annotations_file = '/content/drive/MyDrive/Dhaka-AI 2020/handlabelEnsemble/handlabel ground truth.csv'\n",
        "  detections_file = '/content/drive/MyDrive/Dhaka-AI 2020/handlabelEnsemble/final_output.csv'\n",
        "\n",
        "  mAP = 0\n",
        "  mAP = mAP + mean_average_precision_for_boxes(annotations_file, detections_file, 0.5)\n",
        "  mAP = mAP + mean_average_precision_for_boxes(annotations_file, detections_file, 0.55)\n",
        "  mAP = mAP + mean_average_precision_for_boxes(annotations_file, detections_file, 0.6)\n",
        "  mAP = mAP + mean_average_precision_for_boxes(annotations_file, detections_file, 0.65)\n",
        "  mAP = mAP + mean_average_precision_for_boxes(annotations_file, detections_file, 0.7)\n",
        "  mAP = mAP + mean_average_precision_for_boxes(annotations_file, detections_file, 0.75)\n",
        "  mAP = mAP / 6\n",
        "  print('MAP: ')\n",
        "  print(mAP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySDdO8cFxffB",
        "outputId": "b4733153-1cde-453c-b404-c01afbb55850"
      },
      "source": [
        "ensemble_normalized(0.2)\n",
        "calculate_map()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of files in annotations: 149\n",
            "Number of files in predictions: 146\n",
            "Unique classes: 18\n",
            "Detections length: 146\n",
            "Annotations length: 149\n",
            "Number of files in annotations: 149\n",
            "Number of files in predictions: 146\n",
            "Unique classes: 18\n",
            "Detections length: 146\n",
            "Annotations length: 149\n",
            "Number of files in annotations: 149\n",
            "Number of files in predictions: 146\n",
            "Unique classes: 18\n",
            "Detections length: 146\n",
            "Annotations length: 149\n",
            "Number of files in annotations: 149\n",
            "Number of files in predictions: 146\n",
            "Unique classes: 18\n",
            "Detections length: 146\n",
            "Annotations length: 149\n",
            "Number of files in annotations: 149\n",
            "Number of files in predictions: 146\n",
            "Unique classes: 18\n",
            "Detections length: 146\n",
            "Annotations length: 149\n",
            "Number of files in annotations: 149\n",
            "Number of files in predictions: 146\n",
            "Unique classes: 18\n",
            "Detections length: 146\n",
            "Annotations length: 149\n",
            "MAP: \n",
            "0.3147721239337679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTGLXoognrVv"
      },
      "source": [
        "  params = {\n",
        "      'run_type': 'wbf',\n",
        "      'skip_box_thr': 0.001,\n",
        "      'intersection_thr': 0.5,\n",
        "      'conf_type': 'avg',\n",
        "      'limit_boxes': 30000,\n",
        "      'verbose': False,\n",
        "  }\n",
        "  '''eff5_512_e66_set1.csv\t    eff6_512_e71_set1.csv   yolov5_set1_exp32.csv\n",
        "  eff5_640_e63_set1.csv\t    yolov5_set1_exp123.csv  yolov5_set1_exp60.csv\n",
        "  eff5_prevbest_e69_set1.csv  yolov5_set1_exp155.csv  yolov5_set1_exp63.csv'''\n",
        "  in_dir = '/content/drive/MyDrive/Dhaka-AI 2020/handlabelEnsemble/'\n",
        "  benchmark_csv = [\n",
        "        in_dir + 'TestdataHandlabel_pred_eff_model_1.csv',\n",
        "        in_dir + 'TestdataHandlabel_pred_eff_model_2.csv',\n",
        "        in_dir + 'TestdataHandlabel_pred_eff_model_3.csv',\n",
        "        in_dir + 'TestdataHandlabel_pred_eff_model_4.csv',\n",
        "        in_dir + 'hand_exp32.csv',\n",
        "        in_dir + 'hand_exp60.csv',\n",
        "        in_dir + 'hand_exp63.csv',\n",
        "        in_dir + 'hand_exp123.csv',\n",
        "        in_dir + 'hand_exp155.csv',\n",
        "  ]\n",
        "  expno=1\n",
        "  for w in [1]:\n",
        "    weights = [15,15,45,30,5,5,15,25,20]\n",
        "    print(benchmark_csv)\n",
        "    print(weights)\n",
        "    assert(len(benchmark_csv) == len(weights))\n",
        "    ensemble(benchmark_csv, weights, params, expno)\n",
        "    ensemble_conf(0.2, expno)\n",
        "    ensemble_normalized(expno,0.2)\n",
        "    calculate_map(expno)\n",
        "    expno+=1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}