{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TEST_sadia_efficientdet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGbMv2CnpW2M",
        "outputId": "c178d6c9-06ed-47a9-eeac-85b98d8140de"
      },
      "source": [
        "effdet_no = 5\n",
        "try :\n",
        "    effdet_no = int(input(\"What efficientdet do you want to use for prediction? (0/1/2/3/4/5/6/7) \\n\"))\n",
        "except :\n",
        "    effdet_no = 5\n",
        "if effdet_no>7 :\n",
        "    effdet_no = 5\n",
        "print(\"Using Effdet\",effdet_no)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What efficientdet do you want to use for prediction? (0/1/2/3/4/5/6/7) \n",
            "5\n",
            "Using Effdet 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p011qQvygpZz",
        "outputId": "6ddf5b99-6412-4323-9f16-dfbfa7153f6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAjSs9AC3-BW",
        "outputId": "a2440910-5a7c-478c-dd2f-f42280f00045"
      },
      "source": [
        "!pip install effdet==0.1.6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting effdet==0.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/8b/e54c990312c53e13bdbc04769fa99baf1e0c2aaac528e1048805cef21c51/effdet-0.1.6-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.6/dist-packages (from effdet==0.1.6) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from effdet==0.1.6) (0.8.1+cu101)\n",
            "Collecting timm>=0.1.28\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/2d/39ecc56fbb202e1891c317e8e44667299bc3b0762ea2ed6aaaa2c2f6613c/timm-0.3.2-py3-none-any.whl (244kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->effdet==0.1.6) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->effdet==0.1.6) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->effdet==0.1.6) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.4->effdet==0.1.6) (0.8)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->effdet==0.1.6) (7.0.0)\n",
            "Installing collected packages: timm, effdet\n",
            "Successfully installed effdet-0.1.6 timm-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNnuOMb3R5uw"
      },
      "source": [
        "# !pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPsX7tuQYXqJ"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "httDbTKFZPhB"
      },
      "source": [
        "# ! git clone https://github.com/NVIDIA/apex\n",
        "# os.chdir('apex')\n",
        "# ! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
        "# os.chdir('../')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBT-tYG53qux"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Tmbvt3f9d6",
        "outputId": "a274a64a-3133-4e6e-e3ca-a6413721c12b"
      },
      "source": [
        "#!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install albumentations==0.4.6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/33/1c459c2c9a4028ec75527eff88bc4e2d256555189f42af4baf4d7bd89233/albumentations-0.4.6.tar.gz (117kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
            "\u001b[K     |████████████████████████████████| 952kB 18.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.16.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.10.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.1.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (4.4.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-cp36-none-any.whl size=65165 sha256=3226611d3a1d082394054d3ae868934ffc6c5fdef747b64f5c471825315786db\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/f4/89/56d1bee5c421c36c1a951eeb4adcc32fbb82f5344c086efa14\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZvLvDSDIp_X"
      },
      "source": [
        "import albumentations as A\n",
        "# from apex import amp\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import albumentations as A\n",
        "from albumentations.augmentations.transforms import RandomRain, RandomSnow, RandomFog\n",
        "from albumentations.pytorch.transforms import ToTensorV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2JC2M0Ef-E2"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/timm_efficientdet_pytorch\")\n",
        "sys.path.insert(0, \"/content/omegaconf\")\n",
        "sys.path.insert(0, \"/content/weightedboxesfusion\")\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time\n",
        "import random\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "\n",
        "from glob import glob\n",
        "from skimage import io\n",
        "\n",
        "\n",
        "np.random.seed(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOZw6w3YVt9t"
      },
      "source": [
        "TEST_ROOT_PATH = '/content/drive/My Drive/Dhaka-AI 2020/dataset/test round 2'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JKEfvHywK_Y",
        "outputId": "c9584351-7552-4dda-d0a4-ad95f3155ac5"
      },
      "source": [
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Dec  7 18:09:42 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NHswjDQ2O1Er",
        "outputId": "ec50714e-7cc8-469f-f11e-39f5e0148e3f"
      },
      "source": [
        "!pip install omegaconf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting omegaconf\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl\n",
            "Collecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version == \"3.6\" in /usr/local/lib/python3.6/dist-packages (from omegaconf) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from omegaconf) (3.7.4.3)\n",
            "Building wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=2133add48ce317e744c9134554669b0c1b28aa67de2362210ecaa727c76059de\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: PyYAML, omegaconf\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.3.1 omegaconf-2.0.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsfHSIdSW7eh",
        "outputId": "703b3175-e0ca-444b-b23b-2ff65fcb6d13"
      },
      "source": [
        "!pip install ensemble-boxes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ensemble-boxes\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/b8/ecf44eaf796feee16a32dab193fcbbb625c61a188be47c7616aa020bc97c/ensemble_boxes-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ensemble-boxes) (1.18.5)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from ensemble-boxes) (0.48.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ensemble-boxes) (1.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->ensemble-boxes) (50.3.2)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->ensemble-boxes) (0.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->ensemble-boxes) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ensemble-boxes) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->ensemble-boxes) (1.15.0)\n",
            "Installing collected packages: ensemble-boxes\n",
            "Successfully installed ensemble-boxes-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_gZPYoNlCFYF",
        "outputId": "1fd4fa5a-c79a-4a48-a0c2-e98d0e6b3d15"
      },
      "source": [
        "sys.path.insert(0, \"/content/weightedboxesfusion\")\n",
        "\n",
        "from ensemble_boxes import *\n",
        "from effdet import get_efficientdet_config, EfficientDet, DetBenchPredict\n",
        "from effdet.efficientdet import HeadNet\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-fc07484f7f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mensemble_boxes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meffdet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_efficientdet_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEfficientDet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDetBenchPredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meffdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficientdet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeadNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/effdet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientdet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientDet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbench\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetBenchPredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDetBenchTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munwrap_bench\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFastMapEvalluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_efficientdet_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_detection_model_configs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfactory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/effdet/bench.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelEma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAnchorLabeler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_detections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_DETECTION_POINTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetectionLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/effdet/anchors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatched_nms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_small_boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meffdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_detection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgMaxMatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFasterRcnnBoxCoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBoxList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIouSimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargetAssigner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msoft_nms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatched_soft_nms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/effdet/object_detection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# https://github.com/tensorflow/tpu/tree/master/models/official/retinanet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0margmax_matcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgMaxMatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbox_coder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFasterRcnnBoxCoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbox_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBoxList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/effdet/object_detection/box_coder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbox_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBoxList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Box coder types.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/effdet/object_detection/box_list.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBoxList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;34m\"\"\"Box collection.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_rcb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0m_rcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateResolutionCallbackFromFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_frames_up\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m         \u001b[0m_compile_and_register_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualified_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36m_compile_and_register_class\u001b[0;34m(obj, rcb, qualified_name)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_jit_class_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mdefaults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrontend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_args_for_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_script_class_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualified_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_script_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualified_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \nArguments for call are not valid.\nThe following variants are available:\n  \n  aten::remainder.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -> (Tensor(a!)):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.Scalar(Tensor self, Scalar other) -> (Tensor):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -> (Tensor(a!)):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.Tensor(Tensor self, Tensor other) -> (Tensor):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.int(int a, int b) -> (int):\n  Expected a value of type 'int' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder.float(float a, float b) -> (float):\n  Expected a value of type 'float' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder.int_float(int a, float b) -> (float):\n  Expected a value of type 'int' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder.float_int(float a, int b) -> (float):\n  Expected a value of type 'float' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder(Scalar a, Scalar b) -> (Scalar):\n  Expected a value of type 'number' for argument 'a' but instead found type 'str'.\n\nThe original call is:\n  File \"/usr/local/lib/python3.6/dist-packages/effdet/object_detection/box_list.py\", line 149\n        \"\"\"\n        if not self.has_field(field):\n            raise ValueError('field %s does not exist' % field)\n                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n        self.data[field] = value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJqF1gRlWY37"
      },
      "source": [
        "from random import sample\n",
        "IMG_SIZE = 512\n",
        "DATA_ROOT_PATH = \"/content/drive/My Drive/Dhaka-AI 2020/dataset/test round 2/\"\n",
        "test_images = sorted(glob(DATA_ROOT_PATH + '*'))\n",
        "from random import sample\n",
        "\n",
        "def get_ids(path_list):\n",
        "  path_list = random.sample(path_list,len(path_list))\n",
        "  id_list = [path.split('/')[-1][:-4] for path in path_list]\n",
        "  return np.array(id_list)\n",
        "\n",
        "valid_ids = get_ids(test_images)\n",
        "\n",
        "print(len(valid_ids))\n",
        "# print(valid_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiA4cQQZWY4G"
      },
      "source": [
        "def get_test_transforms():\n",
        "    return A.Compose([\n",
        "            A.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], p=1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qO3bg5hWY4L"
      },
      "source": [
        "class DatasetRetriever(Dataset):\n",
        "\n",
        "    def __init__(self, image_ids, transforms=None):\n",
        "        super().__init__()\n",
        "        self.image_ids = image_ids\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        image_id = self.image_ids[index]\n",
        "        image = cv2.imread(f'{TEST_ROOT_PATH}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        image /= 255.0\n",
        "        if self.transforms:\n",
        "            sample = {'image': image}\n",
        "            sample = self.transforms(**sample)\n",
        "            image = sample['image']\n",
        "        return image, image_id\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.image_ids.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHOXu1eTWY4P"
      },
      "source": [
        "test_data = DatasetRetriever(\n",
        "    image_ids=valid_ids,\n",
        "    transforms=get_test_transforms()\n",
        ")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "data_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    drop_last=False,\n",
        "    collate_fn=collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQyQYZV13Dys"
      },
      "source": [
        "CHECKPOINT_PATH = '/content/drive/MyDrive/Dhaka-AI 2020/effdet_best_weights/effdet5_512_4'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9ejuVYcalda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d314a31d-2ade-4fe1-a5ba-3b6d65e1de58"
      },
      "source": [
        "get_efficientdet_config??"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Object `get_efficientdet_config` not found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IrXAvNwWY4V"
      },
      "source": [
        "Epoch = 0\n",
        "\n",
        "def load_net(checkpoint_path):\n",
        "    config = get_efficientdet_config('tf_efficientdet_d'+str(effdet_no))\n",
        "    net = EfficientDet(config, pretrained_backbone=False)\n",
        "    config.num_classes = 21\n",
        "    config.image_size=IMG_SIZE\n",
        "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    Epoch = checkpoint['epoch']\n",
        "    print(Epoch)\n",
        "\n",
        "    del checkpoint\n",
        "    gc.collect()\n",
        "\n",
        "    net = DetBenchPredict(net, config)\n",
        "    net.eval();\n",
        "    return Epoch,net.cuda()\n",
        "\n",
        "Epoch,net = load_net(CHECKPOINT_PATH +'/last-checkpoint.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IyOCx_uWY4X"
      },
      "source": [
        "def make_predictions(images, score_threshold=0.23):\n",
        "    \n",
        "    images = torch.stack(images).cuda().float()\n",
        "    predictions = []\n",
        "    img_scale = torch.tensor([[1.] for _ in range(images.shape[0])]).cuda().float()\n",
        "    img_size = torch.tensor([(IMG_SIZE, IMG_SIZE) for _ in range(images.shape[0])]).cuda().float()\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        det = net(images,img_scales = img_scale,img_size = img_size)\n",
        "        for i in range(images.shape[0]):\n",
        "            boxes = det[i].detach().cpu().numpy()[:,:4]   \n",
        "            ##----------CHECK HERE 1------------- \n",
        "            scores = det[i].detach().cpu().numpy()[:,4]\n",
        "            ##\n",
        "            classes = det[i].detach().cpu().numpy()[:,5]\n",
        "\n",
        "            ##----------CHECK HERE 2------------- \n",
        "            indexes = np.where(scores > score_threshold)[0]\n",
        "            ##\n",
        "            boxes = boxes[indexes]\n",
        "            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
        "            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
        "            predictions.append({\n",
        "                'boxes': boxes[indexes],\n",
        "                'scores': scores[indexes],\n",
        "                'classes': classes[indexes]\n",
        "            })\n",
        "    return [predictions]\n",
        "\n",
        "def run_wbf(predictions, image_index, image_size=IMG_SIZE, iou_thr=0.44, skip_box_thr=0.43, weights=None):\n",
        "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
        "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
        "    labels = [prediction[image_index]['classes'].tolist()  for prediction in predictions]\n",
        "    ##----------CHECK HERE 3------------- \n",
        "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
        "    boxes = boxes*(image_size-1)\n",
        "    return boxes, scores, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr8A3n9vWY4Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv7ceal9WY4c"
      },
      "source": [
        "\n",
        "# for k in range(0,10):\n",
        "#   i = np.random.RandomState().randint(100)\n",
        "\n",
        "#   for j, (images, image_ids) in enumerate(data_loader):\n",
        "#       if j == i:\n",
        "#           break\n",
        "#   print(image_ids)\n",
        "#   predictions = make_predictions(images)\n",
        "#   i = 0\n",
        "#   sample = images[0].permute(1,2,0).cpu().numpy()\n",
        "\n",
        "#   boxes, scores, labels = run_wbf(predictions, image_index=i)\n",
        "#   boxes = boxes.astype(np.int32).clip(min=0, max=639)\n",
        "\n",
        "#   fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
        "\n",
        "#   for box in boxes:\n",
        "#       cv2.rectangle(sample, (box[0], box[1]), (box[2], box[3]), (1, 0, 0), 1)\n",
        "    \n",
        "#   ax.set_axis_off()\n",
        "#   ax.imshow(sample);\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVbJ6ZxJWY4e"
      },
      "source": [
        "# def showpred(id):\n",
        "    \n",
        "#     dataset = DatasetRetriever(\n",
        "#     image_ids=np.array([id]),\n",
        "#     transforms=get_valid_transforms()\n",
        "#        )\n",
        "\n",
        "\n",
        "\n",
        "#     data_loader = DataLoader(\n",
        "#     dataset,\n",
        "#     batch_size=1,\n",
        "#     shuffle=False,\n",
        "#     num_workers=4,\n",
        "#     drop_last=False,\n",
        "#     collate_fn=collate_fn)\n",
        "\n",
        "#     import matplotlib.pyplot as plt\n",
        "\n",
        "#     for j, (images, image_ids) in enumerate(data_loader):\n",
        "#         break\n",
        "\n",
        "#     predictions = make_predictions(images)\n",
        "\n",
        "#     i = 0\n",
        "#     sample = images[i].permute(1,2,0).cpu().numpy()\n",
        "\n",
        "#     boxes=predictions[0][0]['boxes']\n",
        "#     scores=predictions[0][0]['scores']\n",
        "#     labels=predictions[0][0]['classes']\n",
        "#     boxes = boxes.astype(np.int32).clip(min=0, max=511)\n",
        "\n",
        "#     fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
        "\n",
        "#     for box in boxes:\n",
        "#         cv2.rectangle(sample, (box[0], box[1]), (box[2], box[3]), (1, 0, 0), 1)\n",
        "    \n",
        "#     ax.set_axis_off()\n",
        "#     ax.imshow(sample);\n",
        "    \n",
        "        \n",
        "    \n",
        "# from PIL  import  Image\n",
        "# def showgt(id):\n",
        "    \n",
        "#     img = cv2.imread(f'{TEST_ROOT_PATH}/{image_id}.jpg')\n",
        "#       # opencv always read image as BGR - conversion is must\n",
        "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#     arr=marking_test[marking_test['image_id']==id]\n",
        "#     for x in range(len(arr)):\n",
        "        \n",
        "    \n",
        "#         xm=arr['x'].iloc[x]\n",
        "#         ym=arr['y'].iloc[x]\n",
        "#         width=arr['w'].iloc[x]\n",
        "#         height=arr['h'].iloc[x]\n",
        "    \n",
        "    \n",
        "    \n",
        "      \n",
        "#         #xm,ym,width,height= box\n",
        "#         xmin=xm\n",
        "#         xmax=xm+width\n",
        "#         ymin=ym\n",
        "#         ymax=ym+height\n",
        "#         # converting string to int\n",
        "\n",
        "#         xmin= int(xmin); ymin= int(ymin)\n",
        "#         xmax= int(xmax) ; ymax= int(ymax)\n",
        "\n",
        "      \n",
        "\n",
        "#         img= cv2.rectangle(img,(xmin,ymin), (xmax,ymax),(255,0,0),2)\n",
        "#         img1=cv2.resize(img,(350,350))\n",
        "      \n",
        "#         img1 = Image.fromarray(img1) # cv2 to PIL\n",
        "#     return img1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kzjd8BmWY4h"
      },
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "arr=[]\n",
        "for j, (images, image_ids) in tqdm(enumerate(data_loader)):\n",
        "    \n",
        "    x=images[0]\n",
        "    \n",
        "    predictions = make_predictions(images)\n",
        "    boxes=predictions[0][0]['boxes']\n",
        "    scores=predictions[0][0]['scores']\n",
        "    labels=predictions[0][0]['classes']\n",
        "    '''for i, image in enumerate(images):\n",
        "        boxes, scores, labels = run_wbf(predictions, image_index=i)\n",
        "        boxes = (boxes).round().astype(np.int32).clip(min=0, max=511)\n",
        "        image_id = image_ids[i]\n",
        "        score_threshold = 0.09\n",
        "        indexes = np.where(scores>score_threshold)\n",
        "        boxes = boxes[indexes]\n",
        "        scores = scores[indexes]\n",
        "        labels = labels[indexes]'''\n",
        "    \n",
        "    \n",
        "    #with open('/kaggle/working/valid_results/{}.txt'.format(image_ids[0]),'w') as f:\n",
        "        \n",
        "    \n",
        "    for p  in range(len(boxes)):\n",
        "        arr1=[]\n",
        "        arr2=[]\n",
        "\n",
        "\n",
        "        #f.write('car {} {} {} {} {}\\n'.format(format(scores[p], \".5f\"),int(boxes[p][0]),int(boxes[p][1]),int(boxes[p][2]),int(boxes[p][3])))\n",
        "        arr1.append(image_ids[0])\n",
        "        arr1.append(labels[p])\n",
        "        arr1.append((format(scores[p], \".5f\")))\n",
        "        arr1.append(int(float(boxes[p][0])*(1024*1.0/IMG_SIZE)))\n",
        "        arr1.append(int(float(boxes[p][1])*(1024*1.0/IMG_SIZE)))\n",
        "        arr1.append(int(float(boxes[p][2])*(1024*1.0/IMG_SIZE)))\n",
        "        arr1.append(int(float(boxes[p][3])*(1024*1.0/IMG_SIZE))) #[image.shape[1]]+ [image.shape[0]]\n",
        "        arr1.append(int(1024))\n",
        "        arr1.append(int(1024))\n",
        "        arr.append(arr1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzDPqUzhWY4k"
      },
      "source": [
        "pd.DataFrame(data=arr,index=None,columns=['image_id','class','score','xmin','ymin','xmax','ymax','width','height'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAmHWIL4WY4m"
      },
      "source": [
        "df_pred=pd.DataFrame(data=arr,index=None,columns=['image_id','class','score','xmin','ymin','xmax','ymax','width','height'])\n",
        "df_pred.to_csv(r'./pred_df.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKWUXjbZWY4o"
      },
      "source": [
        "len(df_pred['image_id'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjoFuXLoWY4q"
      },
      "source": [
        "grouped_df = pd.read_csv('/content/drive/My Drive/Dhaka-AI 2020/dataset/classname_codes.csv')\n",
        "grouped_df = grouped_df.drop(columns = ['Unnamed: 0'])\n",
        "grouped_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZybqyhgFWY4s"
      },
      "source": [
        "left = df_pred\n",
        "right = grouped_df\n",
        "\n",
        "left['class'] = left['class'].map(right.set_index('class')['classname'])\n",
        "test_result = left\n",
        "test_result = test_result.drop_duplicates()\n",
        "\n",
        "test_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJPQh4l-XSxd"
      },
      "source": [
        "test_result.to_csv('/content/drive/My Drive/Dhaka-AI 2020/Code/sadia_effdet_test_result/effdet'+str(effdet_no)+'512_4_'+str(Epoch)+'.csv',index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-YxVJiU8msb"
      },
      "source": [
        "test_result[test_result['xmin']<0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPyHQ8rbPGgr"
      },
      "source": [
        "test_result[test_result['xmax']>1024]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCFS3mWdPLew"
      },
      "source": [
        "test_result[test_result['ymin']<0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl4mA-ABPLe0"
      },
      "source": [
        "test_result[test_result['ymax']>1024]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6vDeQ2aaR22"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}